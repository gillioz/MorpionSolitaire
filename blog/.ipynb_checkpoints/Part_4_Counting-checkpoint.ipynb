{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Going deeper with a counting problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To cover**:\n",
    "- regression problem instead of classification\n",
    "- how to evaluate accuracy?\n",
    "- how to generate well-normalized data? i.e. check the frequency of labels\n",
    "- use deeper network but with smaller kernel size: better learning?\n",
    "- how many parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is about *deep* learning, but nothing so far is remotely deep. The model discussed in [the last part](/2022/01/07/Part_3_Binary_problem.html) was so shallow that it could have easily been trained by hand. \n",
    "\n",
    "In this post, we will explore the possibility of training a much deeper neural network, one in which we will give up control and let the data speak for itself. Not only that, but we will also address a more complicated problem: *counting* how many moves are possible on a given grid.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A deeper neural network\n",
    "\n",
    "Let us begin with the network. Instead of having one convolutional layer with a big kernel doing all the work, we slice our model into several layers. The advantage of doing so is that each individual layer need not be as complicated.\n",
    "\n",
    "Our first layer will be a convolutional layer with a 3 x 3 kernel and stride 3: \n",
    "its goal is to decompose the grid into blocks of 3 x 3 pixels, each corresponding to a point (the pixel at the center), and to the 8 segments attached to it, pointing in all directions.\n",
    "\n",
    "After that, we add four more convolutional layer with kernel size 2 x 2. Their role is to examine the relations between nearest neighbors. The inputs of the first of these layers is a block of 3 x 3 pixels; its ouputs have a receiptive field of 2 x 2 blocks, or 6 x 6 pixels. After 4 layers, the receptive field is 5 x 5 blocks, or 15 x 15 pixels. This is sufficient to detect the relevant features that are spreading over 13 x 13 pixels at most.\n",
    "\n",
    "To keep track of sufficiently many possible combinations of neighboring blocks, we use 40 channels in each layer, except in the first one where we use 20 channels. This number is motivated by the fact that there are 5 combinations of lines and dots in 4 directions that give a possible move, and therefore 20 different features to discover. Using twice as many channel should be sufficient to do so.\n",
    "\n",
    "The rest of the network consists of a pooling layer, followed by a couple of linear layers to turn the output into a single number. As a warm-up, we shall train the network on the same problem as [last time](/2022/01/07/Part_3_Binary_problem.html). For this we shall use max pooling and two linear layers only.\n",
    "\n",
    "In summary, the network architecture is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hide\n",
    "# graph = Digraph('Descartes architecture', format='png')\n",
    "# graph.attr('node', fontsize='12')\n",
    "# graph.attr('edge', fontsize='10', arrowsize='0.7')\n",
    "# graph.node('0', label='Grid image')\n",
    "# graph.node('1', label='Convolutional layer, 3 x 3 kernel, stride 3 \\n + ReLu', shape='box', \n",
    "#            style='filled', fillcolor='lightpink')\n",
    "# graph.node('2', label='Convolutional layer, 2 x 2 kernel, stride 1 \\n + ReLu', shape='box', \n",
    "#            style='filled', fillcolor='lightpink')\n",
    "# graph.node('3', label='Convolutional layer, 2 x 2 kernel, stride 1 \\n + ReLu', shape='box', \n",
    "#            style='filled', fillcolor='lightpink')\n",
    "# graph.node('4', label='Convolutional layer, 2 x 2 kernel, stride 1 \\n + ReLu', shape='box', \n",
    "#            style='filled', fillcolor='lightpink')\n",
    "# graph.node('5', label='Convolutional layer, 2 x 2 kernel, stride 1', shape='box', \n",
    "#            style='filled', fillcolor='lightpink')\n",
    "# graph.node('6', label='Max pool', shape='invhouse', \n",
    "#            style='filled', fillcolor='gray90')\n",
    "# graph.node('7', label='Linear layer + ReLu', shape='box', \n",
    "#            style='filled', fillcolor='aquamarine')\n",
    "# graph.node('8', label='Linear layer', shape='box', \n",
    "#            style='filled', fillcolor='aquamarine')\n",
    "# graph.node('9', label='Output')\n",
    "# graph.edge('0','1', label='  1 x  94 x 94')\n",
    "# graph.edge('1','2', label='  20 x  32 x 32')\n",
    "# graph.edge('2','3', label='  40 x  31 x 31')\n",
    "# graph.edge('3','4', label='  40 x  30 x 30')\n",
    "# graph.edge('4','5', label='  40 x  29 x 29')\n",
    "# graph.edge('5','6', label='  40 x  28 x 28')\n",
    "# graph.edge('6','7', label='  40')\n",
    "# graph.edge('7','8', label='  10')\n",
    "# graph.edge('8','9', label='  1')\n",
    "# graph.render('Part_4_Counting_images/Descartes_binary_archi')\n",
    "# graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](Part_4_Counting_images/Descartes_binary_archi.png 'A deeper network for the same problem.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has 23,181 trainable parameters. This more than three times as much as our last model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on the binary problem\n",
    "\n",
    "The larger number of parameters together with the increased depth of this network increases the risk of overfitting the data. Indeed, if we use a static set of 20,000 grids as we did last time, the network easily reaches 100% accuracy on the training set, while saturating at around 90% accuracy on a validation set.\n",
    "\n",
    "We shall therefore use a dynamic data set, as discussed in [Part 2](/2022/01/05/Part_2_Data.html): each grid is used for training 8 times (once in each orientation), then discarded and replaced by a new one, generated on the spot.\n",
    "\n",
    "\n",
    "more epochs needed\n",
    "\n",
    "but more stable training: double learning rate: 0.01 \n",
    "\n",
    "\n",
    "doing great!\n",
    "\n",
    "this is how the accuracy evolves over 200 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](Part_4_Counting_images/Descartes_binary_accuracy.png 'Accuracy going straight up to 100%!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reaching 100%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting: a more difficult problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data\n",
    "\n",
    "play game at random.\n",
    "let's say the final score is $n$.\n",
    "then rewind by $i$ moves, where $i$ is a random number between $0$ and $n$, chosen with probablity\n",
    "$$\n",
    "p_i = \\frac{6}{n (n + 1) (2n + 1)} (n - i)^2\n",
    "$$\n",
    "this probability decreases with the square of $i$: \n",
    "gives a high chance of rewinding by only a few moves, a much smaller chance of rewinding by many moves\n",
    "\n",
    "for each final game, the label is given by the number of allowed moves to be found at that stage.\n",
    "this is something that is part of the implementation, so no additional computation needed.\n",
    "this is the frequency of labels that we obtain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](Part_4_Counting_images/labels_counting.png 'legend')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "computed on 20,000 games, gives a pretty smooth distribution of labels\n",
    "\n",
    "then, we turn this integer number of possible moves (let's call it $N$) into a real number $y$ in the interval $[0,1]$ using\n",
    "$$\n",
    "y = \\frac{N}{N + 5}\n",
    "$$\n",
    "$y$ is zero if there are no possible moves, and it approaches 1 if there are many possible moves\n",
    "\n",
    "this choice gives a mean value $\\mu(y) \\approx 0.5$, and a standard deviation $\\sigma(y) \\approx 0.25$\n",
    "\n",
    "this is the value that the network will try to match;\n",
    "from the output, we can recove the number of possible moves using the inverse relation\n",
    "$$\n",
    "N = \\frac{5 y}{1 - y}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "deeper model *and* regression requires much more data for training\n",
    "\n",
    "more epochs\n",
    "\n",
    "dynamical data: play games as we train; otherwise easy to overfit the data with this deeper network and many parameters\n",
    "\n",
    "show loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking forward\n",
    "\n",
    "so far this problem does not need deep learing; computing the number of possible moves for a given computation is something that can easily be programmed by hand;\n",
    "already here it is nice that the network can check the number for many grids at once, hence slightly improving the efficiency; but also not quite as precise as an explicit computation\n",
    "\n",
    "but we are making big progress towards our goal:\n",
    "all ingredients are here! deep neural network, complicated distribution of labels, regression problem\n",
    "\n",
    "ready to apply these methods to the actual problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide\n",
    "# graph = Digraph('Descartes architecture', format='png')\n",
    "# graph.attr('node', fontsize='12')\n",
    "# graph.attr('edge', fontsize='10', arrowsize='0.7')\n",
    "# graph.node('0', label='Grid image')\n",
    "# graph.node('1', label='Convolutional layer, 3 x 3 kernel, stride 3 \\n + ReLu', shape='box', \n",
    "#            style='filled', fillcolor='lightpink')\n",
    "# graph.node('2', label='Convolutional layer, 2 x 2 kernel, stride 1 \\n + ReLu', shape='box', \n",
    "#            style='filled', fillcolor='lightpink')\n",
    "# graph.node('3', label='Convolutional layer, 2 x 2 kernel, stride 1 \\n + ReLu', shape='box', \n",
    "#            style='filled', fillcolor='lightpink')\n",
    "# graph.node('4', label='Convolutional layer, 2 x 2 kernel, stride 1 \\n + ReLu', shape='box', \n",
    "#            style='filled', fillcolor='lightpink')\n",
    "# graph.node('5', label='Convolutional layer, 2 x 2 kernel, stride 1 \\n + ReLu', shape='box', \n",
    "#            style='filled', fillcolor='lightpink')\n",
    "# graph.node('6', label='Average pool', shape='invhouse', \n",
    "#            style='filled', fillcolor='gray90')\n",
    "# graph.node('7', label='Linear layer + ReLu', shape='box', \n",
    "#            style='filled', fillcolor='aquamarine')\n",
    "# graph.node('8', label='Linear layer', shape='box', \n",
    "#            style='filled', fillcolor='aquamarine')\n",
    "# graph.node('9', label='Output')\n",
    "# graph.edge('0','1', label='  1 x  94 x 94')\n",
    "# graph.edge('1','2', label='  20 x  32 x 32')\n",
    "# graph.edge('2','3', label='  40 x  31 x 31')\n",
    "# graph.edge('3','4', label='  40 x  30 x 30')\n",
    "# graph.edge('4','5', label='  40 x  29 x 29')\n",
    "# graph.edge('5','6', label='  40 x  28 x 28')\n",
    "# graph.edge('6','7', label='  40')\n",
    "# graph.edge('7','8', label='  10')\n",
    "# graph.edge('8','9', label='  1')\n",
    "# graph.render('Part_4_Counting_images/Descartes_architecture')\n",
    "# graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
