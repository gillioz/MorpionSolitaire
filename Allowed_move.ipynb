{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning to predict whether there is one legal move or not\n",
    "\n",
    "This is a simplified version in which the model only answers the question whether there is at least one legal move or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MorpionSolitaire import *\n",
    "from DeepLearningMS import *\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocess import Pool\n",
    "pool = Pool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing one game at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_game(index = 0): # dummy argument needed for passing to pool.map\n",
    "    game = NewGame('cross').play()\n",
    "    grid1 = torch.FloatTensor(game.grid.image())\n",
    "    game = game.unplay(np.random.randint(0, game.score))\n",
    "    grid2 = torch.FloatTensor(game.grid.image())\n",
    "    return torch.unsqueeze(torch.stack((grid1, grid2)), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(grid):\n",
    "    return Image.fromarray(~np.array(torch.squeeze(grid)).astype('bool'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_of_games = play_one_game(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 94, 94])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_of_games.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 94, 94])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_of_games[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAF4AAABeAQAAAACCqZ7DAAAA/ElEQVR4nO1TPWoCQRT+ZpXVREJERCxTpUjnDaawj0fwBkkdEKaysfEIghdIlXYXcoBcIKAWdhbpDGZ2vhTLezMnkCCZZubj+5n3HjOG0FVlSNY/ODt4rjeSZPggSV8z3CZMaRJm0EoCjpWLoPNTRs98vImeYr8UpnIN5MKY0Qwv6hlZA2HC4ztziTaDm/7Jiey+PURBepDkG4CN3PM57eYrKadnASseB6Ahsh4MvMpApxW8YqoV4MHunpQ5uLvYz7XdbbXt5qRVKsi+PRJwZTUgZIt0vD6ON+CWlH78+hhloWxG2RdmURYKJmn12GEIgAaA/Kz6/Ife28WAX4AXuY0qcuw3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=94x94 at 0x7F273D9F21F0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize(pair_of_games[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAF4AAABeAQAAAACCqZ7DAAAA3UlEQVR4nGP8zwAHf5kYkMAoh+6cAgj1////////nf//////PxCZ/w+QZA4wIsmIcSAZ8P0PEocvA4mz+gYSZ/8ThGkNzAxscNMsaxnmw2V2OjAKw2WOH/7/mYGBgYGFgYGBwY6X5SPCtB8s/5A4X7cgOAmsAQiOA7JPLd4ZwE17cIj5DFxG4MD/JrgLNjAkMMBd4HWEuR6ujInhfwNc2T9ogEBCR1QLKXR+yjbA9fy/qOEA5zBuUEBwGE4wIALkHwP///////9hgQj8QLj6H8S9EM4fqFbG0fwzCDgApaF76y9nxUwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=94x94 at 0x7F273C1B5DF0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize(pair_of_games[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(batch_size = 100):\n",
    "    x = torch.cat(pool.map(play_one_game, range(batch_size // 2)))\n",
    "    y = torch.tensor([0.,1.]).repeat(batch_size // 2).unsqueeze(1)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = generate_batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 1, 94, 94]), torch.Size([10, 1]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAF4AAABeAQAAAACCqZ7DAAAA/ElEQVR4nO1TPWoCQRT+ZpXVREJERCxTpUjnDaawj0fwBkkdEKaysfEIghdIlXYXcoBcIKAWdhbpDGZ2vhTLezMnkCCZZubj+5n3HjOG0FVlSNY/ODt4rjeSZPggSV8z3CZMaRJm0EoCjpWLoPNTRs98vImeYr8UpnIN5MKY0Qwv6hlZA2HC4ztziTaDm/7Jiey+PURBepDkG4CN3PM57eYrKadnASseB6Ahsh4MvMpApxW8YqoV4MHunpQ5uLvYz7XdbbXt5qRVKsi+PRJwZTUgZIt0vD6ON+CWlH78+hhloWxG2RdmURYKJmn12GEIgAaA/Kz6/Ife28WAX4AXuY0qcuw3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=94x94 at 0x7F273C1C31F0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAF4AAABeAQAAAACCqZ7DAAAA3UlEQVR4nGP8zwAHf5kYkMAoh+6cAgj1////////nf//////PxCZ/w+QZA4wIsmIcSAZ8P0PEocvA4mz+gYSZ/8ThGkNzAxscNMsaxnmw2V2OjAKw2WOH/7/mYGBgYGFgYGBwY6X5SPCtB8s/5A4X7cgOAmsAQiOA7JPLd4ZwE17cIj5DFxG4MD/JrgLNjAkMMBd4HWEuR6ujInhfwNc2T9ogEBCR1QLKXR+yjbA9fy/qOEA5zBuUEBwGE4wIALkHwP///////9hgQj8QLj6H8S9EM4fqFbG0fwzCDgApaF76y9nxUwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=94x94 at 0x7F273C1C37F0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = MSDataFrame(generate_batch, repeat = 3, size = 100)\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mini-batches stored: 25\n",
      "Number of times a mini-batch is used: 8\n",
      "Number of mini-batches created: 25\n"
     ]
    }
   ],
   "source": [
    "df = MSDataFrame(generate_batch, repeat = 1, size = 25)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = df.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAF4AAABeAQAAAACCqZ7DAAAAwElEQVR4nO3RvwnCYBAF8JcYMRZiekFSWEdxCt3GDcwE4hTOELDJDgopgvgtIKSwUPjMs4heronYaJXrfvC4P5xDSD1cqGrxb5hCoTAKfgWQZIkhSVoPAJxjrmK3UOE6V8h2CslEdTtfSNK6AMD0XsfKtBtLLO4YyNCpRSaxAggEocanSxVMgEIQ+BVA0mKE3ntoZ7+JxhJzl/lK4EQnI4ty0V+TtBW2Xn0cZo+mdZpx8BSSCq8vDNQX+F23Fj/CE4zbZ8UUhOMJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=94x94 at 0x7F273C170C70>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 1, 94, 94]), torch.Size([100, 1]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 40, stride = 3, kernel_size = 13, padding = 0),\n",
    "    torch.nn.AdaptiveMaxPool2d(1),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(40, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_func(outputs, labels):\n",
    "    return ((outputs > 0.5) == labels).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_func(y_pred, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 40\n",
    "length = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85586f2c85e1431f83ceee87ce4df67f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]  loss: 0.289   accuracy: 0.75\n",
      "[1]  loss: 0.186   accuracy: 0.73\n",
      "[2]  loss: 0.163   accuracy: 0.76\n",
      "[3]  loss: 0.148   accuracy: 0.77\n",
      "[4]  loss: 0.134   accuracy: 0.79\n",
      "[5]  loss: 0.127   accuracy: 0.84\n",
      "[6]  loss: 0.119   accuracy: 0.80\n",
      "[7]  loss: 0.115   accuracy: 0.81\n",
      "[8]  loss: 0.111   accuracy: 0.86\n",
      "[9]  loss: 0.113   accuracy: 0.87\n",
      "[10]  loss: 0.114   accuracy: 0.91\n",
      "[11]  loss: 0.114   accuracy: 0.84\n",
      "[12]  loss: 0.110   accuracy: 0.88\n",
      "[13]  loss: 0.110   accuracy: 0.90\n",
      "[14]  loss: 0.109   accuracy: 0.87\n",
      "[15]  loss: 0.106   accuracy: 0.88\n",
      "[16]  loss: 0.106   accuracy: 0.88\n",
      "[17]  loss: 0.099   accuracy: 0.90\n",
      "[18]  loss: 0.091   accuracy: 0.92\n",
      "[19]  loss: 0.090   accuracy: 0.92\n",
      "[20]  loss: 0.094   accuracy: 0.91\n",
      "[21]  loss: 0.096   accuracy: 0.93\n",
      "[22]  loss: 0.099   accuracy: 0.90\n",
      "[23]  loss: 0.089   accuracy: 0.91\n",
      "[24]  loss: 0.092   accuracy: 0.90\n",
      "[25]  loss: 0.093   accuracy: 0.88\n",
      "[26]  loss: 0.083   accuracy: 0.93\n",
      "[27]  loss: 0.088   accuracy: 0.91\n",
      "[28]  loss: 0.085   accuracy: 0.91\n",
      "[29]  loss: 0.087   accuracy: 0.85\n",
      "[30]  loss: 0.083   accuracy: 0.87\n",
      "[31]  loss: 0.081   accuracy: 0.91\n",
      "[32]  loss: 0.084   accuracy: 0.87\n",
      "[33]  loss: 0.079   accuracy: 0.88\n",
      "[34]  loss: 0.080   accuracy: 0.89\n",
      "[35]  loss: 0.080   accuracy: 0.92\n",
      "[36]  loss: 0.081   accuracy: 0.90\n",
      "[37]  loss: 0.083   accuracy: 0.90\n",
      "[38]  loss: 0.079   accuracy: 0.91\n",
      "[39]  loss: 0.079   accuracy: 0.91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in trange(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i in range(length):\n",
    "        inputs, labels = df.read()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        df.iterate()\n",
    "        running_loss += loss.item()\n",
    "    print('[%d]  loss: %.3f   accuracy: %.2f' %\n",
    "          (epoch, running_loss / length,\n",
    "           accuracy_func(outputs, labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mini-batches stored: 25\n",
      "Number of times a mini-batch is used: 8\n",
      "Number of mini-batches created: 150\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO:**\n",
    "- try to add more intermediate channels in ConvNet\n",
    "- try adding another linear layer (?)\n",
    "- implement validation check and examine mistakes\n",
    "\n",
    "**Question:** is it possible to visualize the first layer of the convnet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
