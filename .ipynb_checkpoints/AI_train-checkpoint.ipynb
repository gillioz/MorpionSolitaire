{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning Morpion Solitaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Google Colab, needs to upgrade `fastai` to newest version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade fastai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `fastai` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marc/anaconda3/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.callback.hook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data when running in Google Colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls -l 'gdrive/MyDrive/Colab Notebooks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar -xf 'gdrive/MyDrive/Colab Notebooks/data.tar.gz'\n",
    "# !ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 30000, 30000, 30000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = ['data/run_0_cross', 'data/run_0_pipe', 'data/run_0_random']\n",
    "data_grids = []\n",
    "data_n_avg = []\n",
    "data_n_std = []\n",
    "data_n_max = []\n",
    "for path in paths:\n",
    "    data = np.load(Path(path)/'grids.npy')\n",
    "    data_grids += [data[i] for i in range(len(data))]\n",
    "    data = np.load(Path(path)/'n.npy')\n",
    "    data_n_avg += [data[i][0] for i in range(len(data))]\n",
    "    data_n_std += [data[i][1] for i in range(len(data))]\n",
    "    data_n_max += [data[i][2] for i in range(len(data))]\n",
    "len(data_grids), len(data_n_avg), len(data_n_std), len(data_n_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(zip(data_grids, data_n_avg, data_n_std, data_n_max),\n",
    "                  columns = ['grid', 'n_avg', 'n_std', 'n_max']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    30000.000000\n",
       "mean        38.516633\n",
       "std         24.206661\n",
       "min          0.000000\n",
       "25%         14.000000\n",
       "50%         44.000000\n",
       "75%         60.000000\n",
       "max         89.000000\n",
       "Name: n_max, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['n_max'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization function for grid data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image(grid):\n",
    "    w = 3 * grid.shape[1] - 2\n",
    "    h = 3 * grid.shape[2] - 2\n",
    "    im = np.empty((w, h), dtype=bool)\n",
    "    im[0::3,0::3] = grid[0,:,:]\n",
    "    im[1::3,0::3] = grid[1,:-1,:]\n",
    "    im[2::3,0::3] = grid[1,:-1,:]\n",
    "    im[0::3,1::3] = grid[2,:,:-1]\n",
    "    im[0::3,2::3] = grid[2,:,:-1]\n",
    "    im[1::3,1::3] = grid[3,:-1,:-1]\n",
    "    im[2::3,2::3] = grid[3,:-1,:-1]\n",
    "    im[1::3,2::3] = grid[4,1:,:-1]\n",
    "    im[2::3,1::3] = grid[4,1:,:-1]\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(grid):\n",
    "    return Image.fromarray(~image(grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADEAAAAxAQAAAABb53yxAAAApElEQVR4nK2QsQnCUBRFz79+wYCFBGcQt9BSOxG30CIThG8qG8FRMkJKbZwhA1jYGUR4Fi8j5DaHe4rH4wYD4Cw8w7NrEyDizLsmzvCoGhDhWjYg2FoCLMHKUmQ/vTYg8vsPEPnpBYjvbu73u9jzAIi3Lk5zXyt2INoFE5AVGYCsfo7WINnRGpCljXuWABJ5/3/Wc1x2EEGV9+D+EwqDSMZtgJ3+RHorYa7nrVIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=49x49 at 0x7F9E255F17F0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize(df['grid'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['n_max'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum values of `n`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['n_max'].loc[df['n_max'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADEAAAAxAQAAAABb53yxAAAAXklEQVR4nLXPwQmAMAyF4T+lh47hKJ2oO7iCEzmKW1ihGA/x0IAFEczlwXd5L6IAzAG7H7IVy7h431ghwETuXWGHgEDqvR6SIZJQdd5OzHnp5Xa/R6E+9Y52Dv/6lBchER0PWN3f5QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=49x49 at 0x7F9E25836EE0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize(df['grid'].loc[df['n_max'].idxmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['n_max'].loc[df['n_max'].idxmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADEAAAAxAQAAAABb53yxAAAAvElEQVR4nKXQoQvCQBTH8e+ep2zJOYwK+y8E05qwahCb/gfDv2CCwb/FbJaBZdFoVwRNawrTneEtGDR55cMd737v3TkWgKWg6x8T1a5rjbpvqYOX+nBSECiIQOBACAI5Pgj3VZGDUFZsQcCxCxCaVTAHwUk9vReVmuPWueHnPIbM030vU4PaTkoGQmM63mn+uQJsAS2bCu14cwWBUT8BA3F3BgKXY6b1J+1bTbTf8Fa/96mKq5pf/+R/OX8D0isuPFfTGY0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=49x49 at 0x7F9E2584A460>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize(df['grid'].loc[df['n_max'].idxmin()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID_SIZE = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `x` value is a grid of size `GRID_SIZE x GRID_SIZE`, with the actual grid loaded from the dataframe inserted at a random position. In addition, we add a random mirror flip and a random rotation (not implemented yet!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x(data):\n",
    "    im = image(data['grid'])\n",
    "    # rotate the image at random\n",
    "    im = np.rot90(im, np.random.randint(4))\n",
    "    # flip the image at random\n",
    "    if np.random.randint(2) == 1:\n",
    "        im = np.fliplr(im)\n",
    "    w = (im.shape[0] + 2) // 3\n",
    "    h = (im.shape[1] + 2) // 3\n",
    "    if w < GRID_SIZE:\n",
    "        i = np.random.randint(GRID_SIZE - w)\n",
    "    else:\n",
    "        i = 0\n",
    "    if h < GRID_SIZE:\n",
    "        j = np.random.randint(GRID_SIZE - h)\n",
    "    else:\n",
    "        j = 0\n",
    "    grid = torch.zeros((5, GRID_SIZE, GRID_SIZE))\n",
    "    grid[0,i:i+w,j:j+h] = torch.tensor(im[0::3,0::3].astype(float))\n",
    "    grid[1,i:i+w-1,j:j+h] = torch.tensor(im[1::3,0::3].astype(float))\n",
    "    grid[2,i:i+w,j:j+h-1] = torch.tensor(im[0::3,1::3].astype(float))\n",
    "    grid[3,i:i+w-1,j:j+h-1] = torch.tensor(im[1::3,1::3].astype(float))\n",
    "    grid[4,i+1:i+w,j:j+h-1] = torch.tensor(im[1::3,2::3].astype(float))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADEAAAAxAQAAAABb53yxAAAApElEQVR4nK2QsQnCUBRFz79+wYCFBGcQt9BSOxG30CIThG8qG8FRMkJKbZwhA1jYGUR4Fi8j5DaHe4rH4wYD4Cw8w7NrEyDizLsmzvCoGhDhWjYg2FoCLMHKUmQ/vTYg8vsPEPnpBYjvbu73u9jzAIi3Lk5zXyt2INoFE5AVGYCsfo7WINnRGpCljXuWABJ5/3/Wc1x2EEGV9+D+EwqDSMZtgJ3+RHorYa7nrVIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=49x49 at 0x7F9E2584A340>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize(df['grid'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEYAAABGAQAAAABZVd8pAAAAsUlEQVR4nN2RsQ3CUBBD3/8k4pcIRE8BG7AbbUZADMECFNDlD0FHkZQUFKQLUhJT5H52AFeWfLZ1d06M6D0Jv85iV9wAkFRKUueBjaltfSSp10ndTilLamOfieVFBDLkoQI8rjrnSd0OEXBqn24j6DPCu8ktL9SDtT2YW1sTUlvoAMjg1V9s7r5e2Vw7OwE4yYOg97hyL/PGXTE6huhKSR2SDlXaKFukjXwYU+xAf/PpL2xtWa4SRmjvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=70x70 at 0x7F9E255F1820>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize(get_x(df.iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `y`, we want a number distributed around 0, based on `n` that is a non-negative integer (positive or zero), potentially unbounded. We define\n",
    "$$\n",
    "y(n) = \\frac{\\log(n+1)}{\\log(n_* + 1)} - 1,\n",
    "$$\n",
    "so that $y(0) = -1$, $y(n_*) = 0$, $y(n_*(n_* + 2)) = 1$.\n",
    "\n",
    "If we take $n_*$ small, say for instance $n_* = 1$, then the model will discriminate best among low values of $n$; if on the contrary we take $n_*$ big, then the model will discriminate best among large values of $n$.\n",
    "\n",
    "We will take $n_* = 10$, so that $\\log(n_* + 1) \\approx 2.4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGNSTAR = 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y(data):\n",
    "    n = torch.tensor([data['n_max']]).float()\n",
    "    return torch.log(n + 1)/LOGNSTAR - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define the inverse function, that takes `y` to `n`.\n",
    "$$\n",
    "n(y) = \\exp\\left[ \\log(n_* + 1) (y + 1) \\right] - 1\n",
    "$$\n",
    "This will be useful for inference at the end of the day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_of_y(y):\n",
    "    return torch.exp(LOGNSTAR* (y + 1)) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataBlock and DataLoaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblock = DataBlock(get_x = get_x, get_y = get_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(df, bs = 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check one batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([250, 5, 24, 24]), torch.Size([250, 1]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch, y_batch = to_cpu(dls.one_batch())\n",
    "x_batch.shape, y_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7702],\n",
       "        [ 0.5672],\n",
       "        [-0.0845],\n",
       "        [ 0.7060],\n",
       "        [ 0.4030],\n",
       "        [ 0.4308],\n",
       "        [ 0.5473],\n",
       "        [ 0.4030],\n",
       "        [-0.3294],\n",
       "        [ 0.5574]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the **metrics**, we compute `n` from the model predictions, round up the result to the nearest integer and compare with the target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_accuracy(inputs, targets):\n",
    "    n_pred = torch.round(n_of_y(inputs))\n",
    "    n_targ = torch.round(n_of_y(targets))\n",
    "    return torch.where(n_pred == n_targ, 1.0, 0.0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can ask the result to be within 20% accuracy of the actual number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_ten(inputs, targets):\n",
    "    n_pred = torch.round(n_of_y(inputs))\n",
    "    n_targ = torch.round(n_of_y(targets))\n",
    "    return torch.where(torch.abs(n_pred - n_targ) < 0.2 * n_targ, 1.0, 0.0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_twenty(inputs, targets):\n",
    "    n_pred = torch.round(n_of_y(inputs))\n",
    "    n_targ = torch.round(n_of_y(targets))\n",
    "    return torch.where(torch.abs(n_pred - n_targ) < 0.2 * n_targ, 1.0, 0.0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the network architecture:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small network for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = nn.Sequential(\n",
    "#     # stem: use 3 layers with 3x3 kernel, and quite a few parameters\n",
    "#     nn.Conv2d(5, 32, stride = 1, kernel_size = 3, padding = 0),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(32, 128, stride = 1, kernel_size = 3, padding = 0),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(128, 512, stride = 1, kernel_size = 3, padding = 0),\n",
    "#     nn.ReLU(),\n",
    "#     # flattening\n",
    "#     nn.AdaptiveMaxPool2d(1),\n",
    "#     Flatten(),\n",
    "#     # another couple of linear layers to perform basic operations\n",
    "#     nn.Linear(512, 256),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(256, 128),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(128, 64),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(64, 1)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    ConvLayer(5, 32, padding = 0),\n",
    "    ConvLayer(32, 128, padding = 0),\n",
    "    ConvLayer(128, 512, padding = 0),\n",
    "    nn.AdaptiveMaxPool2d(1),\n",
    "    Flatten(),\n",
    "    LinBnDrop(512, 512, act=nn.ReLU()),\n",
    "    LinBnDrop(512, 512, act=nn.ReLU()),\n",
    "    LinBnDrop(512, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigger network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    ConvLayer(5, 32, padding = 0),\n",
    "    ConvLayer(32, 128, padding = 0),\n",
    "    ConvLayer(128, 512, padding = 0),\n",
    "    ConvLayer(512, 2048, padding = 0),\n",
    "    ConvLayer(2048, 2048, padding = 0),\n",
    "    ConvLayer(2048, 2048, padding = 0),\n",
    "    ConvLayer(2048, 2048, padding = 0),\n",
    "    nn.AdaptiveMaxPool2d(1),\n",
    "    Flatten(),\n",
    "    LinBnDrop(2048, 2048, act=nn.ReLU()),\n",
    "    LinBnDrop(2048, 2048, act=nn.ReLU()),\n",
    "    LinBnDrop(2048, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([250, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch_pred = net(x_batch)\n",
    "x_batch_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0240), tensor(0.0480), tensor(0.0480))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_accuracy(x_batch_pred, y_batch), n_ten(x_batch_pred, y_batch), n_twenty(x_batch_pred, y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, net, loss_func = nn.MSELoss(),\n",
    "                metrics = [n_accuracy, n_ten, n_twenty],\n",
    "                cbs = ActivationStats(with_hist = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(20, lr_max = 5.0e-3) # 5.0e-3 for smaller model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.activation_stats.plot_layer_stats(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.activation_stats.plot_layer_stats(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.activation_stats.color_dim(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.activation_stats.color_dim(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.export(fname = 'models/model_0.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(net, 'models/model_0.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO**: implement a function that infers `n` using the model, and then compare the predictions with the actual value of `n`, as well as with the 1- and 2-sigma confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(data_grids[0:1000]).float()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pred = n_of_y(net(x).data).squeeze()\n",
    "n_val = torch.tensor(data_n_max[0:1000])\n",
    "n_std = torch.tensor(data_n_std[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pred[0:10], n_val[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_sigma(sigma):\n",
    "    return torch.where(torch.abs(n_pred - n_val) < 0.5 + sigma * n_std, 1.0, 0.0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_sigma(0), accuracy_sigma(1), accuracy_sigma(2), accuracy_sigma(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid, y_valid = dls.valid.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(x_valid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_valid = n_of_y(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid[0], n_of_y(y_valid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_preds = net(x_valid).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_preds.squeeze().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_preds.squeeze().std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_preds = n_of_y(x_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack([n_preds.squeeze(), n_valid.squeeze()]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_preds.squeeze().mean(), n_preds.squeeze().std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
