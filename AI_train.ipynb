{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning Morpion Solitaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Google Colab, needs to upgrade `fastai` to newest version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade fastai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `fastai` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marc/anaconda3/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.callback.hook import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data when running in Google Colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls -l 'gdrive/MyDrive/Colab Notebooks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar -xf 'gdrive/MyDrive/Colab Notebooks/data.tar.gz'\n",
    "# !ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = ['data/run_0_cross', 'data/run_0_pipe', 'data/run_0_random']\n",
    "# data_grids = []\n",
    "# data_n = []\n",
    "# for path in paths:\n",
    "#     data = np.load(Path(path)/'grids.npy')\n",
    "#     data_grids += [data[i] for i in range(len(data))]\n",
    "#     data = np.load(Path(path)/'n.npy')\n",
    "#     data_n += [data[i] for i in range(len(data))]\n",
    "# len(data_grids), len(data_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 30000, 30000, 30000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = ['data/run_0_cross', 'data/run_0_pipe', 'data/run_0_random']\n",
    "data_grids = []\n",
    "data_n_avg = []\n",
    "data_n_std = []\n",
    "data_n_max = []\n",
    "for path in paths:\n",
    "    data = np.load(Path(path)/'grids.npy')\n",
    "    data_grids += [data[i] for i in range(len(data))]\n",
    "    data = np.load(Path(path)/'n.npy')\n",
    "    data_n_avg += [data[i][0] for i in range(len(data))]\n",
    "    data_n_std += [data[i][1] for i in range(len(data))]\n",
    "    data_n_max += [data[i][2] for i in range(len(data))]\n",
    "len(data_grids), len(data_n_avg), len(data_n_std), len(data_n_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check data shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 15, 15), (5, 17, 17), (5, 17, 17))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_grids[0].shape, data_grids[10000].shape, data_grids[20000].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization function for grid data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(grid):\n",
    "    size = 3 * grid.shape[2] - 2\n",
    "    im = np.empty((size, size), dtype=bool)\n",
    "    im[0::3,0::3] = grid[0,:,:]\n",
    "    im[1::3,0::3] = grid[1,:-1,:]\n",
    "    im[2::3,0::3] = grid[1,:-1,:]\n",
    "    im[0::3,1::3] = grid[2,:,:-1]\n",
    "    im[0::3,2::3] = grid[2,:,:-1]\n",
    "    im[1::3,1::3] = grid[3,:-1,:-1]\n",
    "    im[2::3,2::3] = grid[3,:-1,:-1]\n",
    "    im[1::3,2::3] = grid[4,1:,:-1]\n",
    "    im[2::3,1::3] = grid[4,1:,:-1]\n",
    "    return Image.fromarray(~im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACsAAAArAQAAAADJJkxtAAAAv0lEQVR4nIXPMUpDURQA0fMuX6IYNXYWlkHchPBLwbW4BgNuIKuwtgs2GnADYpFOfdmABCxETf61SBorq4GpZkrCPID/0P3BkpDliEaZ3RF8Qua0ZA2ebwgmQ+SCXg39Qwuh+yoj8nYtl62B8N4aaByflLGwXQ+qYFrG5L29SQ2vw96TsG9rpDF7W/WE3bP+qRCthcbH9eqH/D7fuapyOW6yNuLiBdm167J2fbTBY59gat15mVV2D5l1I0tmYf4LDDRJr4BvRHwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=43x43 at 0x7F9A340734F0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize(data_grids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_n_max[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADEAAAAxAQAAAABb53yxAAAAgUlEQVR4nLXQsQ3CQBBE0XerCxxSAAGlQEOIChBQAaIhUwiBS3B4geUjOCd2DJt87dcEs5squIc2f+CkJ8hOK/85VzL7V9tL83Wce0IaouXfi7+phJm0EGGaLgglPxFGkA1p13WyY1r3KW5Itabt3ddCljw2+danE+v+w8LDL/70BRM/IfrMEFinAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=49x49 at 0x7F9AB50A9C10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize(data_grids[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_n_max[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum values of `n`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(data_n_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADEAAAAxAQAAAABb53yxAAAAd0lEQVR4nLXQsRGCUBCE4Y8bAuzCUgithgpMbIGKKMOQEghfwPAM3gWiqV6yM3+wu7ddBY/Q7g+6T6lz05J8sxCsRoKl8XpXCJWBcKTPbqqEovlsyZ8OhJs45Zbkwxef0BvM9Z1XLbfjcuq/Zs9r9vz8q59/sNML6zof31h3VeQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=49x49 at 0x7F9A34073910>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize(data_grids[np.argmax(data_n_max)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(zip(data_grids, data_n_avg, data_n_std, data_n_max),\n",
    "                         columns = ['grid', 'n_avg', 'n_std', 'n_max']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID_SIZE = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `x` value is a grid of size `GRID_SIZE x GRID_SIZE`, with the actual grid loaded from the dataframe inserted at a random position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x(data):\n",
    "    grid = data['grid']\n",
    "    c, w, h = grid.shape\n",
    "    if w < GRID_SIZE:\n",
    "        px = np.random.randint(GRID_SIZE - w)\n",
    "    else:\n",
    "        px = 0\n",
    "    if h < GRID_SIZE:\n",
    "        py = np.random.randint(GRID_SIZE - h)\n",
    "    else:\n",
    "        py = 0\n",
    "    x = torch.zeros((c, GRID_SIZE, GRID_SIZE))\n",
    "    x[:,px:px+w,py:py+h] = torch.tensor(grid)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADEAAAAxAQAAAABb53yxAAAAtElEQVR4nKXQsU3EQBQE0Lf/bDAJooQjpAiQU7ogJaIFE5JRAMGVciFklOASlohFWF6CNTkSk7xspJlUwWNo+Y95c9jsml/9SEddE0FJE0E2Erw7ELzWZ8LH08Mpob9fgrDeLgjd+ctKyFdDIeSzJRPmk+87wqhvfXatXxlnQVweZ0HdO1I/i5s6dbqlroQoVkLKFkI6KASjTLA3E1w4Egy19b/t2r7rtZm2H9K07f/1L//9AEpHNo58mgRpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=49x49 at 0x7F9A315075B0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize(dataframe['grid'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADEAAAAxAQAAAABb53yxAAAAtElEQVR4nKXQsU3EQBQE0Lf/bDAJooQjpAiQU7ogJaIFE5JRAMGVciFklOASlohFWF6CNTkSk7xspJlUwWNo+Y95c9jsml/9SEddE0FJE0E2Erw7ELzWZ8LH08Mpob9fgrDeLgjd+ctKyFdDIeSzJRPmk+87wqhvfXatXxlnQVweZ0HdO1I/i5s6dbqlroQoVkLKFkI6KASjTLA3E1w4Egy19b/t2r7rtZm2H9K07f/1L//9AEpHNo58mgRpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=49x49 at 0x7F9A34073040>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize(get_x(dataframe.iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `y` value is a 2-plet containing the maximum of `n` and its standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_y(data):\n",
    "#     return (torch.tensor(data['n_max']).float(),\n",
    "#            torch.tensor(data['n_std']).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `y`, we want a number between 0 and 1, based on `n` that is a non-negative integer (positive or zero), potentially unbounded. We map it to the unit interval using\n",
    "$$\n",
    "y = \\frac{n + 1}{n + n_* + 2},\n",
    "$$\n",
    "so that $s(0) = 1/(n_* + 2)$, $s(n_*) = 0.5$, and $s(\\infty) = 1$. The distribution of $y$ in the unit interval depends on the choice of $n_*$. If we take $n_*$ small, say for instance $n_* = 1$, then the model will discriminate best among low values of $n$; if on the contrary we take $n_*$ big, then the model will discriminate best among large values of $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STAR = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y(data):\n",
    "    n = torch.tensor([data['n_max']]).float()\n",
    "    return (n + 1) / (n + N_STAR + 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define the inverse function, that takes `y` to `n`. This will be useful for inference at the end of the day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_of_y(y):\n",
    "    return (N_STAR + 1) * y / (1 - y) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_of_x(x):\n",
    "    return (N_STAR + 1) * torch.exp(x) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataBlock and DataLoaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblock = DataBlock(get_x = get_x, get_y = get_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(dataframe, bs = 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check one batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([250, 5, 17, 17]), torch.Size([250, 1]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch, y_batch = dls.one_batch()\n",
    "x_batch.shape, y_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8333],\n",
       "        [0.9718],\n",
       "        [0.9649],\n",
       "        [0.9623],\n",
       "        [0.9574],\n",
       "        [0.9655],\n",
       "        [0.9474],\n",
       "        [0.9710],\n",
       "        [0.6667],\n",
       "        [0.3333]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the network architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = nn.Sequential(\n",
    "#     nn.Conv2d(5, 64, stride = 1, kernel_size = 5, padding = 2),\n",
    "#     nn.BatchNorm2d(64),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(64, 128, stride = 1, kernel_size = 3, padding = 1),\n",
    "#     nn.BatchNorm2d(128),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(128, 256, stride = 1, kernel_size = 3, padding = 1),\n",
    "#     nn.BatchNorm2d(256),\n",
    "#     nn.ReLU(),\n",
    "#     nn.AdaptiveAvgPool2d(1),\n",
    "#     Flatten(),\n",
    "#     nn.Linear(256, 1)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = nn.Sequential(\n",
    "#     nn.Conv2d(5, 30, stride = 1, kernel_size = 5, padding = 2),\n",
    "#     # image size: 32x32\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(30, 60, stride = 2, kernel_size = 3, padding = 1),\n",
    "#     # image size: 16x16\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(60, 120, stride = 2, kernel_size = 3, padding = 1),\n",
    "#     # image size: 8x8\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(120, 120, stride = 2, kernel_size = 3, padding = 1),\n",
    "#     # image size: 4x4\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(120, 120, stride = 2, kernel_size = 3, padding = 1),\n",
    "#     # image size: 2x2\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(120, 1, stride = 2, kernel_size = 3, padding = 1),\n",
    "#     # image size: 1x1\n",
    "#     Flatten()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = xresnet18(c_in=5, n_out=1, ks=5, stride=1, stem_szs=(32,64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    # stem: use 3 layers with 3x3 kernel, and quite a few parameters\n",
    "    nn.Conv2d(5, 32, stride = 1, kernel_size = 3, padding = 1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, 128, stride = 1, kernel_size = 3, padding = 1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(128, 512, stride = 1, kernel_size = 3, padding = 1),\n",
    "    nn.ReLU(),\n",
    "    # flattening\n",
    "    nn.AdaptiveMaxPool2d(1),\n",
    "    Flatten(),\n",
    "    # another couple of linear layers to perform basic operations\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model generically returns a real number $x$ distributed around 0. We first map this to the unit interval using the sigmoid fuction\n",
    "$$ s(x) = \\frac{1}{1 + e^{-x}},$$\n",
    "after which $0 < s < 1$.\n",
    "\n",
    "At the same time, $n$ is a non-negative integer (positive or zero), potentially unbounded. We map it to the unit interval using\n",
    "$$\n",
    "s(n) = \\frac{n + 1}{n + n_* + 2},\n",
    "$$\n",
    "so that $s(0) = 1/(n_* + 2)$, $s(n_*) = 0.5$, and $s(\\infty) = 1$. The distribution of $s$ in the unit interval depends on the choice of $n_*$. If we take $n_*$ small, say for instance $n_* = 1$, then the model will discriminate best among low values of $n$; if on the contrary we take $n_*$ big, then the model will discriminate best among large values of $n$. For now we choose an intermediate value $n_* = 5$.\n",
    "\n",
    "To get from $x$ to $n$ directly, we can use\n",
    "$$\n",
    "    n = (n_* + 1) e^x - 1,\n",
    "$$\n",
    "or conversely\n",
    "$$\n",
    "    x = \\log\\left( \\frac{n + 1}{n_* + 1} \\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the **loss function**, we compute `s` both from the predictions and the targets and return the mean square error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mse_loss(predictions, targets):\n",
    "#     predictions = 1/(1 + torch.exp(-predictions))\n",
    "#     s = (targets[0] + 1)/(targets[0] + 10)\n",
    "#     return torch.square(predictions - s).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the **metrics**, we compute `y` from the model predictions, round up the result to the nearest integer and compare with the target (possibly taking into account the standard deviation given with the target):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def n_accuracy_sigma(inputs, targets, sigma):\n",
    "#     n_pred = 9 * torch.exp(inputs.squeeze(1)) - 1\n",
    "#     return torch.where(torch.abs(n_pred - targets[0]) < 0.5 + sigma * targets[1], 1.0, 0.0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def n_accuracy_0(inputs, targets): return n_accuracy_sigma(inputs, targets, 0)\n",
    "# def n_accuracy_1(inputs, targets): return n_accuracy_sigma(inputs, targets, 1)\n",
    "# def n_accuracy_2(inputs, targets): return n_accuracy_sigma(inputs, targets, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_accuracy(inputs, targets):\n",
    "    n_pred = torch.round(n_of_x(inputs))\n",
    "    n_targ = torch.round(n_of_y(targets))\n",
    "    return torch.where(n_pred == n_targ, 1.0, 0.0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([250, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch_pred = net(x_batch)\n",
    "x_batch_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0360)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_accuracy(x_batch_pred, y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = Learner(dls, net, loss_func = mse_loss,\n",
    "#                 metrics = [n_accuracy_0, n_accuracy_1, n_accuracy_2],\n",
    "#                 cbs = ActivationStats(with_hist = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING**: this is probably a bad loss function for regression, but for now it seems to be working fine..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, net, loss_func = nn.BCEWithLogitsLoss(),\n",
    "                # loss_func = nn.MSELoss()\n",
    "                metrics = n_accuracy,\n",
    "                cbs = ActivationStats(with_hist = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      30.00% [3/10 16:48<39:14]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>n_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.405692</td>\n",
       "      <td>0.367650</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>05:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.363832</td>\n",
       "      <td>0.346753</td>\n",
       "      <td>0.014333</td>\n",
       "      <td>05:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.341821</td>\n",
       "      <td>0.331976</td>\n",
       "      <td>0.025333</td>\n",
       "      <td>05:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='36' class='' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      37.50% [36/96 01:56<03:13 0.3405]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, lr_max = 5.0e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.activation_stats.plot_layer_stats(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.activation_stats.plot_layer_stats(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.activation_stats.color_dim(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.activation_stats.color_dim(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.export(fname = 'models/cross_5T_0.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(net, 'models/test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid, y_valid = dls.valid.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(x_valid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid[0], n_of_y(y_valid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_preds = net(x_valid).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_preds.squeeze().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_preds.squeeze().std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_preds = n_of_x(x_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_preds.squeeze().mean(), n_preds.squeeze().std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
