{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning to predict whether there is one legal move or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MorpionSolitaire import *\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocess import Pool\n",
    "pool = Pool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for visualization of a grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_grid(grid):\n",
    "    size = 3 * grid.shape[2] - 2\n",
    "    im = np.empty((size, size), dtype=bool)\n",
    "    im[0::3,0::3] = grid[0,:,:]\n",
    "    im[1::3,0::3] = grid[1,:-1,:]\n",
    "    im[2::3,0::3] = grid[1,:-1,:]\n",
    "    im[0::3,1::3] = grid[2,:,:-1]\n",
    "    im[0::3,2::3] = grid[2,:,:-1]\n",
    "    im[1::3,1::3] = grid[3,:-1,:-1]\n",
    "    im[2::3,2::3] = grid[3,:-1,:-1]\n",
    "    im[1::3,2::3] = grid[4,1:,:-1]\n",
    "    im[2::3,1::3] = grid[4,1:,:-1]\n",
    "    return Image.fromarray(~im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is generated as follows.\n",
    "1. Play a game until the end, with a random starting grid and random moves\n",
    "1. Add this grid to the batch, with label `0` (= no legal moves)\n",
    "1. Rewind one move\n",
    "1. Explore all possible outcomes of this new game (one or more moves possibles)\n",
    "1. Add this grid to the batch, with label corresponding to the number of legal moves\n",
    "1. Rewind at random to an arbitrary intermediate step\n",
    "1. Add this grid to the batch, with label `2` (= at least two legal moves)\n",
    "1. Repeat the process\n",
    "After `n` iterations, we are left with `3*n` grids, half of which have legal moves left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_game(index = 0):\n",
    "    labels = torch.zeros(3)\n",
    "    game = StartingGame('cross').play()\n",
    "    grid1 = torch.FloatTensor(game.grid)\n",
    "    game = game.unplay(1)\n",
    "    grid2 = torch.FloatTensor(game.grid)\n",
    "    labels[1] = game.explore_depth(2)\n",
    "    game = game.unplay(np.random.randint(game.score) + 1)\n",
    "    grid3 = torch.FloatTensor(game.grid)\n",
    "    labels[2] = 2.0\n",
    "    return torch.stack((grid1, grid2, grid3)), labels.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(batch_size = 240):\n",
    "    xy = pool.map(play_one_game, range(batch_size // 3))\n",
    "    return torch.cat([x[0] for x in xy]), torch.cat([y[1] for y in xy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = generate_batch(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([24, 5, 32, 32]), torch.Size([24, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAF4AAABeAQAAAACCqZ7DAAAA70lEQVR4nO2TsUpDMRSGv6TXUVqkm4IX29UncOngA/gIHVwF36AVi0OhUKqP4AN0Ejeva5+hoItzRyvE/A65yQ2469KzhI//Pyc5J4kRKb4tWezgj0FrqgTmOgCSpHsvSS7knLayAtU0B0fK8bSbHM23jc0/F8m2WXIlSc4ItjM/+aJ+B4V/2RtHm+NwGFZJvnzkIUHn0pxEeKeC4xo+F/3uXTxBcUBejcbm53RSaZU1WIBh66LpZ2WNHUmuALDS7VlUnoC3qJwPekdl7NQOlDaVZ1+KNm5WAAR4/fg9t6BomV9Wmdm0SXOLsfs//wU/3Bi2yPWH2bkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=94x94 at 0x7F9A51B5FC70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_grid(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAF4AAABeAQAAAACCqZ7DAAAA1ElEQVR4nO3TPQ4BURQF4DM/xSjGIFQUiH0QtV4lsQF7YANWoVJNqfKzAZ2ESGQaQSFEI+RxFMN7dwWicLsvOS835yXXIvQ8bIj549uIJM4SnsTBFsj1BW4ylo4EJiOJSpwjyfG6Q5LKBYBNYmViSWy7n5hCvo1PzBnarQUAuABwWaqkflNuqKzZM8ieDWquQGEfaUTTINRITd/FSbLrxEtBkveM1dRQCew0nvCvugLqJc/sqcI0fcI3TdGbQ1fA7ChjgYgxFP+GoojxRJLK+t/PD+AF1BJ9ZN7IxVwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=94x94 at 0x7F99D8B60FD0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_grid(x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.]), tensor([1.]), tensor([2.]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0], y[1], y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.3333), tensor(0.3333), tensor(0.3333))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(y == 0, 1.0, 0.0).mean(), torch.where(y == 1, 1.0, 0.0).mean(), torch.where(y == 2, 1.0, 0.0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the network architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = torch.nn.Sequential(\n",
    "#     torch.nn.Conv2d(5, 15, stride = 1, kernel_size = 2, padding = 0),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Conv2d(15, 30, stride = 1, kernel_size = 2, padding = 0),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Conv2d(30, 60, stride = 1, kernel_size = 2, padding = 0),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Conv2d(60, 120, stride = 1, kernel_size = 2, padding = 0),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.AdaptiveMaxPool2d(1),\n",
    "#     torch.nn.Flatten(),\n",
    "#     torch.nn.Linear(120, 40),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(40, 10),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(10, 1)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    # The first 4 layers are convolutional with kernel size 2\n",
    "    # and relatively few parameters. They are meant to detect\n",
    "    # patterns that extend up to 5 unit cells across.\n",
    "    torch.nn.Conv2d(5, 15, stride = 1, kernel_size = 2, padding = 0),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(15, 30, stride = 1, kernel_size = 2, padding = 0),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(30, 60, stride = 1, kernel_size = 2, padding = 0),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(60, 120, stride = 1, kernel_size = 2, padding = 0),\n",
    "    torch.nn.ReLU(),\n",
    "    # The next 2-3 layers are convolutional with kernel size 3.\n",
    "    # They are meant to detect specific combinations of the above features.\n",
    "    torch.nn.Conv2d(120, 240, stride = 1, kernel_size = 3, padding = 0),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(240, 480, stride = 1, kernel_size = 3, padding = 0),\n",
    "    torch.nn.ReLU(),\n",
    "#     torch.nn.Conv2d(480, 480, stride = 1, kernel_size = 3, padding = 0),\n",
    "#     torch.nn.ReLU(),\n",
    "    # After the convolutional layers, the outputs are averaged over the grid. \n",
    "    torch.nn.AdaptiveAvgPool2d(1),\n",
    "    torch.nn.Flatten(),\n",
    "    # Finally, a few linear layers turn the output into a single number.\n",
    "    torch.nn.Linear(480, 120),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(120, 30),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(30, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of batches in one 'epoch':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_func(outputs, labels):\n",
    "    return torch.where(torch.abs(torch.round(outputs) - labels) == 0, 1.0, 0.0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3333)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_func(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 240\n",
    "n_batches = 25\n",
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9862bf4b2c79470b87324c98bfed3308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marc/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]  loss: 0.940   accuracy: 0.32\n",
      "[2]  loss: 0.711   accuracy: 0.31\n",
      "[3]  loss: 0.699   accuracy: 0.31\n",
      "[4]  loss: 0.699   accuracy: 0.32\n",
      "[5]  loss: 0.703   accuracy: 0.28\n",
      "[6]  loss: 0.701   accuracy: 0.28\n",
      "[7]  loss: 0.697   accuracy: 0.29\n",
      "[8]  loss: 0.701   accuracy: 0.30\n",
      "[9]  loss: 0.712   accuracy: 0.27\n",
      "[10]  loss: 0.709   accuracy: 0.30\n",
      "[11]  loss: 0.704   accuracy: 0.28\n",
      "[12]  loss: 0.706   accuracy: 0.31\n",
      "[13]  loss: 0.703   accuracy: 0.31\n",
      "[14]  loss: 0.695   accuracy: 0.29\n",
      "[15]  loss: 0.702   accuracy: 0.31\n",
      "[16]  loss: 0.702   accuracy: 0.28\n",
      "[17]  loss: 0.698   accuracy: 0.30\n",
      "[18]  loss: 0.702   accuracy: 0.32\n",
      "[19]  loss: 0.690   accuracy: 0.30\n",
      "[20]  loss: 0.690   accuracy: 0.30\n",
      "[21]  loss: 0.658   accuracy: 0.30\n",
      "[22]  loss: 0.600   accuracy: 0.44\n",
      "[23]  loss: 0.551   accuracy: 0.48\n",
      "[24]  loss: 0.542   accuracy: 0.41\n",
      "[25]  loss: 0.547   accuracy: 0.39\n",
      "[26]  loss: 0.540   accuracy: 0.47\n",
      "[27]  loss: 0.544   accuracy: 0.38\n",
      "[28]  loss: 0.525   accuracy: 0.37\n",
      "[29]  loss: 0.520   accuracy: 0.43\n",
      "[30]  loss: 0.532   accuracy: 0.44\n",
      "[31]  loss: 0.503   accuracy: 0.47\n",
      "[32]  loss: 0.517   accuracy: 0.45\n",
      "[33]  loss: 0.508   accuracy: 0.43\n",
      "[34]  loss: 0.499   accuracy: 0.42\n",
      "[35]  loss: 0.462   accuracy: 0.49\n",
      "[36]  loss: 0.449   accuracy: 0.48\n",
      "[37]  loss: 0.412   accuracy: 0.55\n",
      "[38]  loss: 0.519   accuracy: 0.41\n",
      "[39]  loss: 0.522   accuracy: 0.47\n",
      "[40]  loss: 0.466   accuracy: 0.49\n",
      "[41]  loss: 0.463   accuracy: 0.45\n",
      "[42]  loss: 0.512   accuracy: 0.46\n",
      "[43]  loss: 0.428   accuracy: 0.55\n",
      "[44]  loss: 0.421   accuracy: 0.46\n",
      "[45]  loss: 0.421   accuracy: 0.49\n",
      "[46]  loss: 0.406   accuracy: 0.46\n",
      "[47]  loss: 0.404   accuracy: 0.49\n",
      "[48]  loss: 0.395   accuracy: 0.58\n",
      "[49]  loss: 0.430   accuracy: 0.54\n",
      "[50]  loss: 0.384   accuracy: 0.50\n",
      "[51]  loss: 0.401   accuracy: 0.53\n",
      "[52]  loss: 0.372   accuracy: 0.57\n",
      "[53]  loss: 0.358   accuracy: 0.54\n",
      "[54]  loss: 0.377   accuracy: 0.53\n",
      "[55]  loss: 0.364   accuracy: 0.55\n",
      "[56]  loss: 0.370   accuracy: 0.55\n",
      "[57]  loss: 0.373   accuracy: 0.53\n",
      "[58]  loss: 0.377   accuracy: 0.58\n",
      "[59]  loss: 0.367   accuracy: 0.59\n",
      "[60]  loss: 0.328   accuracy: 0.56\n",
      "[61]  loss: 0.360   accuracy: 0.59\n",
      "[62]  loss: 0.352   accuracy: 0.54\n",
      "[63]  loss: 0.379   accuracy: 0.60\n",
      "[64]  loss: 0.335   accuracy: 0.52\n",
      "[65]  loss: 0.320   accuracy: 0.58\n",
      "[66]  loss: 0.317   accuracy: 0.60\n",
      "[67]  loss: 0.342   accuracy: 0.53\n",
      "[68]  loss: 0.340   accuracy: 0.60\n",
      "[69]  loss: 0.309   accuracy: 0.60\n",
      "[70]  loss: 0.318   accuracy: 0.60\n",
      "[71]  loss: 0.292   accuracy: 0.63\n",
      "[72]  loss: 0.310   accuracy: 0.60\n",
      "[73]  loss: 0.281   accuracy: 0.70\n",
      "[74]  loss: 0.290   accuracy: 0.65\n",
      "[75]  loss: 0.322   accuracy: 0.57\n",
      "[76]  loss: 0.298   accuracy: 0.63\n",
      "[77]  loss: 0.310   accuracy: 0.57\n",
      "[78]  loss: 0.344   accuracy: 0.64\n",
      "[79]  loss: 0.281   accuracy: 0.63\n",
      "[80]  loss: 0.295   accuracy: 0.62\n",
      "[81]  loss: 0.270   accuracy: 0.68\n",
      "[82]  loss: 0.269   accuracy: 0.64\n",
      "[83]  loss: 0.273   accuracy: 0.66\n",
      "[84]  loss: 0.304   accuracy: 0.62\n",
      "[85]  loss: 0.252   accuracy: 0.72\n",
      "[86]  loss: 0.268   accuracy: 0.68\n",
      "[87]  loss: 0.267   accuracy: 0.65\n",
      "[88]  loss: 0.276   accuracy: 0.66\n",
      "[89]  loss: 0.273   accuracy: 0.66\n",
      "[90]  loss: 0.263   accuracy: 0.65\n",
      "[91]  loss: 0.286   accuracy: 0.70\n",
      "[92]  loss: 0.315   accuracy: 0.68\n",
      "[93]  loss: 0.240   accuracy: 0.66\n",
      "[94]  loss: 0.234   accuracy: 0.67\n",
      "[95]  loss: 0.245   accuracy: 0.70\n",
      "[96]  loss: 0.243   accuracy: 0.69\n",
      "[97]  loss: 0.255   accuracy: 0.63\n",
      "[98]  loss: 0.237   accuracy: 0.69\n",
      "[99]  loss: 0.236   accuracy: 0.69\n",
      "[100]  loss: 0.236   accuracy: 0.64\n",
      "[101]  loss: 0.271   accuracy: 0.62\n",
      "[102]  loss: 0.247   accuracy: 0.71\n",
      "[103]  loss: 0.211   accuracy: 0.74\n",
      "[104]  loss: 0.223   accuracy: 0.70\n",
      "[105]  loss: 0.230   accuracy: 0.73\n",
      "[106]  loss: 0.213   accuracy: 0.71\n",
      "[107]  loss: 0.237   accuracy: 0.75\n",
      "[108]  loss: 0.216   accuracy: 0.67\n",
      "[109]  loss: 0.223   accuracy: 0.70\n",
      "[110]  loss: 0.216   accuracy: 0.68\n",
      "[111]  loss: 0.239   accuracy: 0.68\n",
      "[112]  loss: 0.235   accuracy: 0.70\n",
      "[113]  loss: 0.211   accuracy: 0.73\n",
      "[114]  loss: 0.238   accuracy: 0.68\n",
      "[115]  loss: 0.226   accuracy: 0.72\n",
      "[116]  loss: 0.249   accuracy: 0.62\n",
      "[117]  loss: 0.255   accuracy: 0.70\n",
      "[118]  loss: 0.232   accuracy: 0.73\n",
      "[119]  loss: 0.243   accuracy: 0.70\n",
      "[120]  loss: 0.230   accuracy: 0.73\n",
      "[121]  loss: 0.235   accuracy: 0.64\n",
      "[122]  loss: 0.234   accuracy: 0.70\n",
      "[123]  loss: 0.236   accuracy: 0.74\n",
      "[124]  loss: 0.237   accuracy: 0.68\n",
      "[125]  loss: 0.228   accuracy: 0.69\n",
      "[126]  loss: 0.209   accuracy: 0.68\n",
      "[127]  loss: 0.209   accuracy: 0.78\n",
      "[128]  loss: 0.199   accuracy: 0.72\n",
      "[129]  loss: 0.236   accuracy: 0.73\n",
      "[130]  loss: 0.220   accuracy: 0.67\n",
      "[131]  loss: 0.228   accuracy: 0.72\n",
      "[132]  loss: 0.216   accuracy: 0.72\n",
      "[133]  loss: 0.218   accuracy: 0.70\n",
      "[134]  loss: 0.231   accuracy: 0.71\n",
      "[135]  loss: 0.196   accuracy: 0.74\n",
      "[136]  loss: 0.206   accuracy: 0.70\n",
      "[137]  loss: 0.203   accuracy: 0.71\n",
      "[138]  loss: 0.193   accuracy: 0.77\n",
      "[139]  loss: 0.213   accuracy: 0.74\n",
      "[140]  loss: 0.228   accuracy: 0.75\n",
      "[141]  loss: 0.182   accuracy: 0.77\n",
      "[142]  loss: 0.193   accuracy: 0.79\n",
      "[143]  loss: 0.183   accuracy: 0.73\n",
      "[144]  loss: 0.199   accuracy: 0.76\n",
      "[145]  loss: 0.182   accuracy: 0.77\n",
      "[146]  loss: 0.191   accuracy: 0.71\n",
      "[147]  loss: 0.197   accuracy: 0.80\n",
      "[148]  loss: 0.193   accuracy: 0.80\n",
      "[149]  loss: 0.202   accuracy: 0.81\n",
      "[150]  loss: 0.180   accuracy: 0.77\n",
      "[151]  loss: 0.193   accuracy: 0.65\n",
      "[152]  loss: 0.222   accuracy: 0.81\n",
      "[153]  loss: 0.184   accuracy: 0.77\n",
      "[154]  loss: 0.175   accuracy: 0.72\n",
      "[155]  loss: 0.217   accuracy: 0.75\n",
      "[156]  loss: 0.186   accuracy: 0.77\n",
      "[157]  loss: 0.178   accuracy: 0.78\n",
      "[158]  loss: 0.180   accuracy: 0.79\n",
      "[159]  loss: 0.187   accuracy: 0.57\n",
      "[160]  loss: 0.183   accuracy: 0.73\n",
      "[161]  loss: 0.175   accuracy: 0.79\n",
      "[162]  loss: 0.169   accuracy: 0.78\n",
      "[163]  loss: 0.167   accuracy: 0.77\n",
      "[164]  loss: 0.155   accuracy: 0.86\n",
      "[165]  loss: 0.154   accuracy: 0.80\n",
      "[166]  loss: 0.145   accuracy: 0.83\n",
      "[167]  loss: 0.160   accuracy: 0.77\n",
      "[168]  loss: 0.190   accuracy: 0.78\n",
      "[169]  loss: 0.162   accuracy: 0.80\n",
      "[170]  loss: 0.159   accuracy: 0.86\n",
      "[171]  loss: 0.194   accuracy: 0.73\n",
      "[172]  loss: 0.169   accuracy: 0.83\n",
      "[173]  loss: 0.169   accuracy: 0.81\n",
      "[174]  loss: 0.181   accuracy: 0.75\n",
      "[175]  loss: 0.191   accuracy: 0.77\n",
      "[176]  loss: 0.165   accuracy: 0.81\n",
      "[177]  loss: 0.147   accuracy: 0.79\n",
      "[178]  loss: 0.177   accuracy: 0.80\n",
      "[179]  loss: 0.153   accuracy: 0.79\n",
      "[180]  loss: 0.180   accuracy: 0.72\n",
      "[181]  loss: 0.170   accuracy: 0.76\n",
      "[182]  loss: 0.155   accuracy: 0.85\n",
      "[183]  loss: 0.159   accuracy: 0.80\n",
      "[184]  loss: 0.146   accuracy: 0.82\n",
      "[185]  loss: 0.142   accuracy: 0.83\n",
      "[186]  loss: 0.132   accuracy: 0.83\n",
      "[187]  loss: 0.162   accuracy: 0.80\n",
      "[188]  loss: 0.158   accuracy: 0.78\n",
      "[189]  loss: 0.154   accuracy: 0.78\n",
      "[190]  loss: 0.146   accuracy: 0.82\n",
      "[191]  loss: 0.149   accuracy: 0.62\n",
      "[192]  loss: 0.180   accuracy: 0.79\n",
      "[193]  loss: 0.165   accuracy: 0.79\n",
      "[194]  loss: 0.159   accuracy: 0.84\n",
      "[195]  loss: 0.130   accuracy: 0.82\n",
      "[196]  loss: 0.135   accuracy: 0.85\n",
      "[197]  loss: 0.156   accuracy: 0.76\n",
      "[198]  loss: 0.147   accuracy: 0.85\n",
      "[199]  loss: 0.137   accuracy: 0.83\n",
      "[200]  loss: 0.148   accuracy: 0.85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in trange(n_epochs * n_batches):\n",
    "    inputs, labels = generate_batch(batch_size)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(inputs)\n",
    "    loss = loss_func(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    running_loss += loss.item()\n",
    "    if (epoch + 1) % n_batches == 0:\n",
    "        print('[%d]  loss: %.3f   accuracy: %.2f' %\n",
    "              ((epoch + 1) // n_batches, running_loss / n_batches,\n",
    "               accuracy_func(outputs, labels)))\n",
    "        running_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = generate_batch(1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = net(x).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8342)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_func(y_preds, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.0392), tensor(0.8396), tensor(1.0917), tensor(0.7327))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean(), y.std(), y_preds.mean(), y_preds.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.stack([y, y_preds]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 0.2866828441619873],\n",
       " [2.0, 1.1915302276611328],\n",
       " [1.0, 0.4013027250766754],\n",
       " [1.0, 0.21605974435806274],\n",
       " [1.0, 0.36961477994918823],\n",
       " [2.0, 1.0833020210266113],\n",
       " [1.0, 0.3285292088985443],\n",
       " [0.0, 1.0517902374267578],\n",
       " [1.0, 1.625229835510254],\n",
       " [1.0, 1.5153495073318481],\n",
       " [1.0, 0.32628682255744934],\n",
       " [0.0, 0.8476131558418274],\n",
       " [0.0, 0.7310764789581299],\n",
       " [1.0, 1.802956461906433],\n",
       " [1.0, 0.4414219856262207],\n",
       " [1.0, 0.4358581304550171],\n",
       " [1.0, 0.3191726505756378],\n",
       " [1.0, 0.444817453622818],\n",
       " [0.0, 0.6732960343360901],\n",
       " [0.0, 0.6668891906738281],\n",
       " [1.0, 0.46725860238075256],\n",
       " [1.0, 0.2660853862762451],\n",
       " [1.0, 0.2499181628227234],\n",
       " [0.0, 0.8115851879119873],\n",
       " [2.0, 1.2992500066757202],\n",
       " [1.0, 0.30235421657562256],\n",
       " [1.0, 0.3390921652317047],\n",
       " [1.0, 0.48853546380996704],\n",
       " [2.0, 1.4272780418395996],\n",
       " [0.0, 0.5443698763847351],\n",
       " [2.0, 1.1918413639068604],\n",
       " [1.0, 0.46988046169281006],\n",
       " [1.0, 0.44638752937316895],\n",
       " [0.0, 1.1503562927246094],\n",
       " [1.0, 1.5153495073318481],\n",
       " [1.0, 0.32628682255744934],\n",
       " [0.0, 0.8476131558418274],\n",
       " [0.0, 0.7310764789581299],\n",
       " [1.0, 1.802956461906433],\n",
       " [1.0, 1.6546967029571533],\n",
       " [0.0, 0.7055200934410095],\n",
       " [1.0, 0.24532997608184814],\n",
       " [1.0, 0.4463689625263214],\n",
       " [1.0, 0.4456915855407715],\n",
       " [0.0, 0.7273280024528503],\n",
       " [1.0, 0.32885438203811646],\n",
       " [2.0, 0.4095415472984314],\n",
       " [1.0, 0.42749062180519104],\n",
       " [1.0, 1.5283915996551514],\n",
       " [1.0, 0.28744369745254517],\n",
       " [2.0, 1.1714051961898804],\n",
       " [1.0, 0.3736756145954132],\n",
       " [2.0, 1.2353510856628418],\n",
       " [1.0, 0.39492136240005493],\n",
       " [0.0, 1.4141055345535278],\n",
       " [1.0, 0.316829115152359],\n",
       " [1.0, 0.26136690378189087],\n",
       " [1.0, 0.2636692523956299],\n",
       " [0.0, 0.5556829571723938],\n",
       " [1.0, 0.28489255905151367],\n",
       " [0.0, 0.5040791034698486],\n",
       " [2.0, 1.2000941038131714],\n",
       " [1.0, 0.35104599595069885],\n",
       " [1.0, 0.3899024724960327],\n",
       " [2.0, 1.3037269115447998],\n",
       " [1.0, 1.5931066274642944],\n",
       " [0.0, 0.5403018593788147],\n",
       " [1.0, 1.5120553970336914],\n",
       " [1.0, 0.3158140778541565],\n",
       " [1.0, 0.3285093307495117],\n",
       " [0.0, 0.5059627890586853],\n",
       " [0.0, 0.508277416229248],\n",
       " [1.0, 0.2008795142173767],\n",
       " [1.0, 0.4414219856262207],\n",
       " [1.0, 0.4358581304550171],\n",
       " [1.0, 0.3191726505756378],\n",
       " [1.0, 0.444817453622818],\n",
       " [0.0, 0.6732960343360901],\n",
       " [1.0, 0.3899024724960327],\n",
       " [2.0, 1.3037269115447998],\n",
       " [1.0, 1.5931066274642944],\n",
       " [0.0, 0.5403018593788147],\n",
       " [1.0, 1.5120553970336914],\n",
       " [1.0, 1.6932042837142944],\n",
       " [0.0, 0.5815842151641846],\n",
       " [1.0, 0.486575186252594],\n",
       " [1.0, 0.3837346136569977],\n",
       " [0.0, 0.811921238899231],\n",
       " [2.0, 1.1754422187805176],\n",
       " [1.0, 0.21923458576202393],\n",
       " [1.0, 1.6641005277633667],\n",
       " [0.0, 0.7865458130836487],\n",
       " [2.0, 1.0925043821334839],\n",
       " [0.0, 0.5293318033218384],\n",
       " [1.0, 1.572643756866455],\n",
       " [2.0, 1.491256594657898],\n",
       " [2.0, 1.1924550533294678],\n",
       " [1.0, 0.3036104440689087],\n",
       " [1.0, 0.3366933763027191],\n",
       " [1.0, 0.3301175534725189],\n",
       " [2.0, 1.0671985149383545],\n",
       " [2.0, 1.229656457901001],\n",
       " [1.0, 0.4135811924934387],\n",
       " [0.0, 0.7366275787353516],\n",
       " [2.0, 1.1703587770462036],\n",
       " [1.0, 0.4975013732910156],\n",
       " [1.0, 0.49963265657424927],\n",
       " [0.0, 0.5220173597335815],\n",
       " [2.0, 0.7793739438056946],\n",
       " [1.0, 0.3022465109825134],\n",
       " [1.0, 0.20877057313919067],\n",
       " [2.0, 1.0003271102905273],\n",
       " [2.0, 0.4246809482574463],\n",
       " [2.0, 0.8751617670059204],\n",
       " [1.0, 0.197187602519989],\n",
       " [2.0, 1.0141046047210693],\n",
       " [0.0, 0.5435379147529602],\n",
       " [2.0, 1.1161491870880127],\n",
       " [1.0, 1.6966278553009033],\n",
       " [0.0, 0.5006740093231201],\n",
       " [2.0, 1.2267628908157349],\n",
       " [0.0, 0.5155455470085144],\n",
       " [1.0, 1.6340820789337158],\n",
       " [1.0, 0.3384893536567688],\n",
       " [0.0, 0.5426681637763977],\n",
       " [1.0, 0.3158140778541565],\n",
       " [1.0, 0.3285093307495117],\n",
       " [0.0, 0.5059627890586853],\n",
       " [0.0, 0.508277416229248],\n",
       " [1.0, 0.2008795142173767],\n",
       " [2.0, 0.7793739438056946],\n",
       " [1.0, 0.3022465109825134],\n",
       " [1.0, 0.20877057313919067],\n",
       " [2.0, 1.0003271102905273],\n",
       " [2.0, 0.4246809482574463],\n",
       " [2.0, 0.8751617670059204],\n",
       " [1.0, 0.197187602519989],\n",
       " [2.0, 1.0141046047210693],\n",
       " [0.0, 0.5435379147529602],\n",
       " [2.0, 1.1161491870880127],\n",
       " [1.0, 1.6966278553009033],\n",
       " [1.0, 0.3142690658569336],\n",
       " [1.0, 0.4540698528289795],\n",
       " [0.0, 0.7785190939903259],\n",
       " [0.0, 0.733454704284668],\n",
       " [2.0, 0.9690241813659668],\n",
       " [1.0, 0.21903574466705322],\n",
       " [0.0, 1.175029993057251],\n",
       " [0.0, 0.7784783840179443],\n",
       " [1.0, 0.3666621744632721],\n",
       " [1.0, 0.32541152834892273],\n",
       " [1.0, 0.27997082471847534],\n",
       " [1.0, 0.37904617190361023],\n",
       " [2.0, 1.4070087671279907],\n",
       " [0.0, 1.1931654214859009],\n",
       " [1.0, 1.812995195388794],\n",
       " [0.0, 0.7507582902908325],\n",
       " [1.0, 0.3638448417186737],\n",
       " [1.0, 0.22573554515838623],\n",
       " [0.0, 0.5415564179420471],\n",
       " [1.0, 0.29086464643478394],\n",
       " [0.0, 1.02549147605896],\n",
       " [0.0, 0.5204111337661743],\n",
       " [1.0, 1.5851624011993408],\n",
       " [2.0, 1.2373640537261963],\n",
       " [2.0, 1.292744755744934],\n",
       " [2.0, 1.482109785079956],\n",
       " [1.0, 0.3062264919281006],\n",
       " [1.0, 1.7050738334655762],\n",
       " [0.0, 0.6085659265518188],\n",
       " [1.0, 1.5292761325836182],\n",
       " [0.0, 0.5840513706207275],\n",
       " [0.0, 0.5097891092300415],\n",
       " [1.0, 0.2807520031929016],\n",
       " [1.0, 1.6522042751312256],\n",
       " [2.0, 0.3171890676021576],\n",
       " [1.0, 0.3954313397407532],\n",
       " [0.0, 0.6037545204162598],\n",
       " [0.0, 0.9188055992126465],\n",
       " [1.0, 0.2650265693664551],\n",
       " [1.0, 1.5031073093414307],\n",
       " [1.0, 0.25625312328338623],\n",
       " [0.0, 0.5006740093231201],\n",
       " [2.0, 1.2267628908157349],\n",
       " [0.0, 0.5155455470085144],\n",
       " [1.0, 1.6340820789337158],\n",
       " [1.0, 0.3384893536567688],\n",
       " [0.0, 0.5426681637763977],\n",
       " [1.0, 0.22573554515838623],\n",
       " [0.0, 0.5415564179420471],\n",
       " [1.0, 0.29086464643478394],\n",
       " [0.0, 1.02549147605896],\n",
       " [0.0, 0.5204111337661743],\n",
       " [1.0, 1.5851624011993408],\n",
       " [2.0, 1.2373640537261963],\n",
       " [2.0, 1.292744755744934],\n",
       " [2.0, 1.482109785079956],\n",
       " [1.0, 0.3062264919281006],\n",
       " [1.0, 1.7050738334655762]]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistakes = []\n",
    "for i in range(y.shape[0]):\n",
    "    if torch.round(y_preds[i]) - y[i] != 0:\n",
    "        mistakes.append([y[i].item(), y_preds[i].item()])\n",
    "mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info about the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param_tensor in net.state_dict():\n",
    "#     print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'models/AI_predict_2_v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning process is going quite well, but the model seems to be missing one of the allowed move\n",
    "(1 in 20 patterns is equivalent to 5%)\n",
    "\n",
    "Let's try with bigger batches!\n",
    "\n",
    "If not working, the next logical thing to do is to use a bigger model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
